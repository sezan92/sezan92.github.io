# Reinforcement Learning Course 1 Week 3

> Notes for Reinforcement Learning Course 1 Week 3.

## TLDR

- Evaluate the policy: How good the policy is?
- Update the policy: Let's improve our actions!
- Dynamic Programming in the context of Reinforcement learning

### Prerequisites

Previous blog , [Reinforcement Learning Course 1, Week 3](https://sezan92.github.io/2023/11/21/RL-course1-w3-blog.html)

## Policy Evaluation

From the previous blog, we came to know about value of a state. We can denote this as $v(s)$. Now the value of a state will depend on two things. One, how easily we can get the maximum reward from the state. Two, is what action we will take, i.e. what policy we will follow on that state! We can denote it as $v_{\pi}(s)$. Which means, the "value of a state while following the policy $\pi$".

![](/images/RL_1_W4_blog/image_1_Policy_Evaluation.png)

From the first blog, we can recall

$v_{\pi} (s) = \displaystyle\sum_a \pi(a|s) \displaystyle\sum_{s'}\displaystyle\sum_r p(s', r|s, a)[r + \gamma v_{\pi} (s')]$ [upto 1:57]